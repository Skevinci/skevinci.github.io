---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>

Hi there! This is Sikai Li ÊùéÊÄùÊ•∑. You can call me Sky or Skevin. I am currently a CS Ph.D. student at the University of North Carolina at Chapel Hill, advised by [Prof. Mingyu Ding](https://dingmyu.github.io/). Previously, I worked as a research assistant with [Prof. Dan Roth](https://www.cis.upenn.edu/~danroth/) at the University of Pennsylvania, and with [Prof. Christoforos Mavrogiannis](https://chrismavrogiannis.com/) and [Prof. Nima Fazeli](https://www.mmintlab.com/people/nima-fazeli/) at the University of Michigan. Before that, I received my B.S. in Computer Science from University of Michigan under the supervision of [Prof. Joyce Chai](https://web.eecs.umich.edu/~chaijy/).

My primary research interest lies at the intersection of robotics and learning methods, and the goal is to ground robots in the real world.
- Humanoid: Reinforcement learning, motion tracking, sim2real
- Learning from Interactions with Environments and Humans: Robot Learning, robot manipulation, task planning, online learning
- Foundation models: commonsense reasoning, open-vocabulary object detection, supervised fine-tuning & DPO

# üî• News
- *2025.01*: &nbsp;üéâüéâ One paper was accepted by ICRA 2025.

<!-- # üìÉ Preprints -->


# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICRA 2025</div><img src='images/arch.png' alt="arch" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Tactile Functasets: Neural Implicit Representations of Tactile Datasets](https://arxiv.org/abs/2409.14592)

**Sikai Li**, Samanta Rodriguez, Yiming Dou, Andrew Owens, Nima Fazeli

\[[**Paper**](https://arxiv.org/abs/2409.14592)] \[[**Project**](https://www.mmintlab.com/tactile-functasets/)] \[[**Code**](https://github.com/MMintLab/tactile_functasets) ]
  - Rather than directly using raw tactile images, we propose neural implicit functions trained to reconstruct the tactile dataset, producing compact representations that capture the underlying structure of the sensory inputs. 
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">MAS @ ICML 2025</div><img src='images/game_intro.png' alt="game" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Communication and Verification in LLM Agents towards Collaboration under Information Asymmetry](https://arxiv.org/abs/2510.25595)

Run Peng\*, Ziqiao Ma\*, Amy Pang, **Sikai Li**, Zhang Xi-Jia, Yingzhuo Yu, Cristian-Paul Bara, Joyce Chai

\[[**Paper**](https://arxiv.org/abs/2510.25595)] \[[**Project**](https://github.com/Roihn/EinsteinPuzzles)] \[[**Code**](https://github.com/Roihn/EinsteinPuzzles) ]
  - We study LLM agents in task collaboration, particularly under the condition of information asymmetry, where agents have disparities in their knowledge and skills and need to work together to complete a shared task.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICRA 2024</div><img src='images/icra_2024.png' alt="icra 2024" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Think, Act, and Ask: Open-World Interactive Personalized Robot Navigation](https://arxiv.org/pdf/2310.07968)

Yinpei Dai, Run Peng, **Sikai Li**, Joyce Chai

\[[**Paper**](https://arxiv.org/pdf/2310.07968)\] \[[**Video**](https://www.youtube.com/watch?v=rN5S8QIhhQc&ab_channel=UMichSLEDLab)\]  \[[**Code**](https://github.com/sled-group/navchat)\]
  - We propose a new framework termed Open-woRld Interactive persOnalized Navigation (ORION), which uses Large Language Models to make sequential decisions to manipulate different modules for perception, navigation and communication.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IMECE 2023</div><img src='images/imece_2023.png' alt="imece 2023" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[An Adaptive Path Planning Approach for Digital Twin-Enabled Robot Arm Based on Inverse Kinematics and Deep Reinforcement Learning](https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2023/87608/V003T03A079/1195595)

Qi Zhou, **Sikai Li**, Jingbo Qu, Jin Wu, Haomiao Xu, Youyi Bi

\[[**Paper**](https://asmedigitalcollection.asme.org/IMECE/proceedings/IMECE2023/87608/V003T03A079/1195595)\]
  - We propose an adaptive path planning approach for robot arm based on Inverse Kinematics and Deep Reinforcement Learning in a pick-and-place context.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Journal of Manufacturing Science and Engineering</div><img src='images/journal_2024.png' alt="journal 2024" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Adaptive Robot Motion Planning for Smart Manufacturing Based on Digital Twin and Bayesian Optimization-Enhanced Reinforcement Learning](https://www.novatechsetproofs.com/authors/ASME/MANU-24-1544.pdf)

Qi Zhou, Jin Wu, Boyan Li, **Sikai Li**, Bohan Feng, Jiangshan Liu, Youyi Bi

\[[**Paper**](https://www.novatechsetproofs.com/authors/ASME/MANU-24-1544.pdf)\]
  - An adaptive robot motion planning approach is proposed based on digital twin and reinforcement learning. The core idea is to adaptively select geometry-based or RL-based methods for robot motion planning through a real-time distance detection mechanism, which can reduce the complexity of RL model training and accelerate the training process.
</div>
</div>

# üìë Projects

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">IROS Late Breaking Results 2023 </div><img src='images/iros_2023.png' alt="iros 2023" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Exploring LLM in Intention Modeling for Human-Robot Collaboration](https://drive.google.com/file/d/1aFDgzGns9qVebKUwHLnvoh9F0rT4H31p/view?usp=sharing)

**Sikai Li**, Run Peng, Yinpei Dai, Jenny Lee, Joyce Chai
\[[**Paper**](https://drive.google.com/file/d/1aFDgzGns9qVebKUwHLnvoh9F0rT4H31p/view?usp=sharing)\]
  - We take an initial step towards Theory of Mind modeling powered by large language models GPT-4 in human-robot communication and collaboration.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">Computer Vision Course Project</div><img src='images/442.png' alt="iros 2023" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Image Generation for Open-World Object Rearrangement](https://drive.google.com/file/d/1tGhGwfF8SYHSOkJ2Vs6ESeEaP2olnFVs/view?usp=sharing)

**Sikai Li**, Haohong Shang
\[[**Paper**](https://drive.google.com/file/d/1tGhGwfF8SYHSOkJ2Vs6ESeEaP2olnFVs/view?usp=sharing)\]
  - Inspired by DALL-E-Bot, we reimplement the vision part of its pipeline and present a improved framework that takes an initial observation image as input and outputs an image with same objects but in a natural and human-like layout.
</div>
</div>


<!-- # üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  -->

# üìñ Educations
- *2025.08 - Now*, Ph.D. in Computer Science, University of North Carolina at Chapel Hill.
- *2022.08 - 2024.05*, BSE in Computer Science & Engineering, University of Michigan.
- *2020.09 - 2025.08*, BSE in Electrical & Computer Engineering, Shanghai Jiao Tong University.

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# üíª Internships and Research Experience
- *2024.09 - 2025.06*, Cognitive Computation Group, University of Pennsylvania. Advised by [Prof. Dan Roth](https://www.cis.upenn.edu/~danroth/), mentored by [Siyi Liu](https://liusiyi641.github.io/).
- *2024.05 - 2024.09*, Fluent Robotics Lab, University of Michigan. Advised by [Prof. Christoforos Mavrogiannis](https://chrismavrogiannis.com/).
- *2024.05 - 2024.09*, MMint Lab, University of Michigan. Advised by [Nima Fazeli](https://www.mmintlab.com/people/nima-fazeli/).
- *2023.05 - 2024.07*, SLED Lab, University of Michigan. Advised by [Prof. Joyce Chai](https://web.eecs.umich.edu/~chaijy/), mentored by [Ziqiao Ma](https://mars-tin.github.io/) and [Yinpei Dai](https://yinpeidai.github.io/).
- *2021.11 - 2023.02*, DIDIS Lab, Shanghai Jiao Tong University. Advised by [Prof. Youyi Bi](https://sites.ji.sjtu.edu.cn/youyibi/people/).
- *2022.06 - 2022.09*, Research and Development Center of Southwest Securities Co., LTD, Shanghai, China.

# üëî Service
- Conference Reviewer for IROS, ICRA, WACV

# üî• Hobbies
- Travel: I love road tripüöó and National Parks, especially the wildlifeüêª. I've been to 27/63 National Parks in the United States. Recommend Mt. Rainier and Bryce Canyon!
- Music: I like to play the piano (ABRSM Grade 8), the saxophoneüé∑ and the guitarüé∏.
- Sports: Love soccer (Liverpoolüî¥üêî), volleyball and badminton.
- Gaming: League of Legends‚û°Ô∏èApex Legends (Master in season 17 ^^)‚û°Ô∏èValorant (Ascendantüíö in EPISODE 7: ACT 3)
- Foods: I admire the Canton-style cuisine.
<div style="text-align: center;">
  <span style="color:black;">Last updated: November 2025</span>
</div>

<script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=6NscyjfbvGgi_XufLZfweEjsTUOdR1aHobXgMCKDJTs&cl=ffffff&w=a"></script>
